{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret[tuners]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQvQf8RA3USn",
        "outputId": "980a9460-adc6-4d21-c015-c13437f694e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycaret[tuners]\n",
            "  Downloading pycaret-3.3.2-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.1/486.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (4.66.4)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (1.25.2)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (2.0.3)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (3.1.4)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (1.11.4)\n",
            "Collecting joblib<1.4,>=1.2.0 (from pycaret[tuners])\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>1.4.0 (from pycaret[tuners])\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyod>=1.1.3 (from pycaret[tuners])\n",
            "  Downloading pyod-2.0.1.tar.gz (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting imbalanced-learn>=0.12.0 (from pycaret[tuners])\n",
            "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting category-encoders>=2.4.0 (from pycaret[tuners])\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (4.1.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (0.58.1)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (2.1.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (8.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (2.2.1)\n",
            "Collecting deprecation>=2.1.0 (from pycaret[tuners])\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting xxhash (from pycaret[tuners])\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (3.7.1)\n",
            "Collecting scikit-plot>=0.3.7 (from pycaret[tuners])\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (5.15.0)\n",
            "Collecting kaleido>=0.2.1 (from pycaret[tuners])\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting schemdraw==0.15 (from pycaret[tuners])\n",
            "  Downloading schemdraw-0.15-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly-resampler>=0.8.3.1 (from pycaret[tuners])\n",
            "  Downloading plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (0.14.2)\n",
            "Collecting sktime==0.26.0 (from pycaret[tuners])\n",
            "  Downloading sktime-0.26.0-py3-none-any.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats>=1.1.3 (from pycaret[tuners])\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima>=2.0.4 (from pycaret[tuners])\n",
            "  Downloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wurlitzer (from pycaret[tuners])\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from pycaret[tuners]) (0.2.7)\n",
            "Collecting optuna>=3.0.0 (from pycaret[tuners])\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna-integration (from pycaret[tuners])\n",
            "  Downloading optuna_integration-3.6.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-optimize>=0.9.0 (from pycaret[tuners])\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tune-sklearn>=0.2.1 (from pycaret[tuners])\n",
            "  Downloading tune_sklearn-0.5.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[tune]>=1.0.0 (from pycaret[tuners])\n",
            "  Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl (66.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret[tuners]) (24.1)\n",
            "Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret[tuners])\n",
            "  Downloading scikit_base-0.7.8-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>1.4.0 (from pycaret[tuners])\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret[tuners]) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[tuners]) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[tuners]) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[tuners]) (0.18.3)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[tuners]) (0.10.9.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret[tuners]) (3.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret[tuners]) (3.19.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.5.0->pycaret[tuners])\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[tuners]) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[tuners]) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[tuners]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[tuners]) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[tuners]) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[tuners]) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[tuners]) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[tuners]) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[tuners]) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret[tuners]) (0.41.1)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0.0->pycaret[tuners])\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna>=3.0.0->pycaret[tuners])\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->pycaret[tuners]) (2.0.31)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->pycaret[tuners]) (6.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret[tuners]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret[tuners]) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret[tuners]) (8.4.2)\n",
            "Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading dash-2.17.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret[tuners]) (3.0.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret[tuners]) (2.0.7)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (3.15.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (1.4.1)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]>=1.0.0->pycaret[tuners])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0->pycaret[tuners]) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret[tuners]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret[tuners]) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret[tuners]) (2024.6.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize>=0.9.0->pycaret[tuners])\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0.0->pycaret[tuners])\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.0.0->pycaret[tuners]) (4.12.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (3.0.3)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting retrying (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret[tuners]) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret[tuners]) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[tuners]) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[tuners]) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret[tuners]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret[tuners]) (0.2.13)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.0.0->pycaret[tuners]) (3.0.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (6.5.5)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (2.2.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.1.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (21.2.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[tuners]) (1.2.1)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.1-py3-none-any.whl size=193267 sha256=5bc37482aeb4a575d77011b736d71fcd712a9af10f767ae6e5c355b91b039c91\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/75/88/b853cf33b0053b0a001dca55b74d515048b7656e736364eb57\n",
            "Successfully built pyod\n",
            "Installing collected packages: kaleido, dash-table, dash-html-components, dash-core-components, xxhash, wurlitzer, tsdownsample, tensorboardX, scikit-base, schemdraw, retrying, pyaml, orjson, Mako, joblib, jedi, deprecation, colorlog, scikit-learn, alembic, sktime, scikit-plot, scikit-optimize, pyod, optuna, imbalanced-learn, dash, ray, pmdarima, plotly-resampler, optuna-integration, category-encoders, tbats, tune-sklearn, pycaret\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.10.1\n",
            "    Uninstalling imbalanced-learn-0.10.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.10.1\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 category-encoders-2.6.3 colorlog-6.8.2 dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 imbalanced-learn-0.12.3 jedi-0.19.1 joblib-1.3.2 kaleido-0.2.1 optuna-3.6.1 optuna-integration-3.6.0 orjson-3.10.6 plotly-resampler-0.10.0 pmdarima-2.0.4 pyaml-24.4.0 pycaret-3.3.2 pyod-2.0.1 ray-2.31.0 retrying-1.3.4 schemdraw-0.15 scikit-base-0.7.8 scikit-learn-1.4.2 scikit-optimize-0.10.2 scikit-plot-0.3.7 sktime-0.26.0 tbats-1.1.3 tensorboardX-2.6.2.2 tsdownsample-0.1.3 tune-sklearn-0.5.0 wurlitzer-3.1.1 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64NSZ_z43UPa",
        "outputId": "9a60756f-7ef0-4e1a-9a14-79eed2c6d54d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "km8IfyHa18yl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from itertools import combinations\n",
        "from xgboost import XGBClassifier\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pycaret.classification import setup, compare_models, create_model, tune_model, plot_model, evaluate_model, finalize_model, predict_model, save_model, load_model\n",
        "from pycaret.classification import get_config\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GetDataKaggle(download_path = \"/content/drive/MyDrive/Colab Notebooks/INTELIGENCIA ARTIFICIAL/PARCIAL 1/data/\",user='albertstats1988',token = 'e1c23ee858429bae18536e17c0f41495'):\n",
        "  # Configurar las credenciales de Kaggle\n",
        "  os.environ['KAGGLE_USERNAME'] = user\n",
        "  os.environ['KAGGLE_KEY'] = token\n",
        "\n",
        "  # Crear instancia de la API de Kaggle y autenticar\n",
        "  api = KaggleApi()\n",
        "  api.authenticate()\n",
        "\n",
        "  # Aceptar las reglas de la competencia (intenta este paso primero)\n",
        "  competition_name = 'playground-series-s4e6'\n",
        "  # Descargar los archivos de la competencia\n",
        "  api.competition_download_files(competition_name, path=download_path)\n",
        "\n",
        "  # Descomprimir los archivos descargados\n",
        "  import zipfile\n",
        "  for item in os.listdir(download_path):\n",
        "    if item.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(os.path.join(download_path, item), 'r')\n",
        "      zip_ref.extractall(download_path)\n",
        "      zip_ref.close()\n",
        "      print(f\"Unzipped {item}\")\n",
        "\n",
        "  path1 = download_path + \"train.csv\"\n",
        "  path2 = download_path + \"test.csv\"\n",
        "  df = pd.read_csv(path1)\n",
        "  prueba =  pd.read_csv(path2)\n",
        "\n",
        "  ct = [\"Marital status\",\"Daytime/evening attendance\",\"Nacionality\",\"Mother's occupation\",\"Father's occupation\",\n",
        "        \"Displaced\",\"Educational special needs\",\"Debtor\",\"Tuition fees up to date\",\"Gender\",\"Scholarship holder\",\"International\",\n",
        "        \"Application mode\",\"Application order\"]\n",
        "  for k in ct:\n",
        "    df[k] = df[k].astype(\"O\")\n",
        "    prueba[k] = prueba[k].astype(\"O\")\n",
        "\n",
        "  return df, prueba"
      ],
      "metadata": {
        "id": "IPdY7kLF2Acm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, prueba  = GetDataKaggle()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtgRAFq45koR",
        "outputId": "397fc2ed-c1ca-4d6d-f65e-8364cf417c3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped playground-series-s4e6.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AUTOML_PyCaret_preprocess_data(df):\n",
        "  def prueba_kr(x):\n",
        "    if x<=0.10:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def criterion_(df,columns):\n",
        "    for k in columns:\n",
        "      df[k] = df[k].map(prueba_kr)\n",
        "    df[\"criterio\"] = np.sum(df.get(columns),axis=1)\n",
        "    df[\"criterio\"] = df.apply(lambda row: 1 if row[\"criterio\"]==3 else 0,axis = 1)\n",
        "    return df\n",
        "\n",
        "  def nombre_(x):\n",
        "    return \"C\"+str(x)\n",
        "\n",
        "  def indicadora(x):\n",
        "    if x==True:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def label_tg(x):\n",
        "    if x==\"Dropout\":\n",
        "      return 0\n",
        "    elif x==\"Enrolled\":\n",
        "      return 1\n",
        "    else:\n",
        "      return 2\n",
        "\n",
        "  def label_tg_inv(x):\n",
        "    if x==0:\n",
        "      return \"Dropout\"\n",
        "    elif x==1:\n",
        "      return \"Enrolled\"\n",
        "    else:\n",
        "      return \"Graduate\"\n",
        "\n",
        "  # Formatos\n",
        "  formato = pd.DataFrame({'Variable': list(df.columns), 'Formato': df.dtypes })\n",
        "  # Cuantitativas\n",
        "  cuantitativas = list(formato.loc[formato[\"Formato\"]!=\"object\",\"Variable\"])\n",
        "  cuantitativas = [x for x in cuantitativas if x not in [\"id\",\"Target\"]]\n",
        "  # Categóricas\n",
        "  categoricas = list(formato.loc[formato[\"Formato\"]==\"O\",\"Variable\"])\n",
        "  categoricas = [x for x in categoricas if x not in [\"id\",\"Target\"]]\n",
        "  # Variables al cuadrado\n",
        "  base_cuadrado = df.get(cuantitativas).copy()\n",
        "  base_cuadrado[\"Target\"] = df[\"Target\"].copy()\n",
        "  var_names2, pvalue1, pvalue2, pvalue3 = [], [], [], []\n",
        "  for k in cuantitativas:\n",
        "    base_cuadrado[k+\"_2\"] = base_cuadrado[k] ** 2\n",
        "    # Prueba de Kruskal sin logaritmo\n",
        "    mue1 = base_cuadrado.loc[base_cuadrado[\"Target\"]==\"Graduate\",k+\"_2\"].to_numpy()\n",
        "    mue2 = base_cuadrado.loc[base_cuadrado[\"Target\"]==\"Dropout\",k+\"_2\"].to_numpy()\n",
        "    mue3 = base_cuadrado.loc[base_cuadrado[\"Target\"]==\"Enrolled\",k+\"_2\"].to_numpy()\n",
        "\n",
        "    p1 = stats.kruskal(mue1,mue2)[1]\n",
        "    p2 = stats.kruskal(mue1,mue3)[1]\n",
        "    p3 = stats.kruskal(mue2,mue3)[1]\n",
        "\n",
        "    # Guardar p values y variables\n",
        "    var_names2.append(k+\"_2\")\n",
        "    pvalue1.append(np.round(p1,2))\n",
        "    pvalue2.append(np.round(p2,2))\n",
        "    pvalue3.append(np.round(p3,2))\n",
        "\n",
        "  pcuadrado1 = pd.DataFrame({'Variable2':var_names2,'p value':pvalue1,'p value 2':pvalue2,'p value 3':pvalue3})\n",
        "  pcuadrado1 = criterion_(pcuadrado1,[\"p value\",\"p value 2\",\"p value 3\"])\n",
        "\n",
        "  # Interacciones cuantitativas\n",
        "  lista_inter = list(combinations(cuantitativas,2))\n",
        "  base_interacciones = df.get(cuantitativas).copy()\n",
        "  var_interaccion, pv1, pv2, pv3 = [], [], [], []\n",
        "  base_interacciones[\"Target\"] = df[\"Target\"].copy()\n",
        "\n",
        "  for k in lista_inter:\n",
        "    base_interacciones[k[0]+\"__\"+k[1]] = base_interacciones[k[0]] * base_interacciones[k[1]]\n",
        "\n",
        "    # Prueba de Kruskal\n",
        "    mue1 = base_interacciones.loc[base_interacciones[\"Target\"]==\"Graduate\",k[0]+\"__\"+k[1]].to_numpy()\n",
        "    mue2 = base_interacciones.loc[base_interacciones[\"Target\"]==\"Dropout\",k[0]+\"__\"+k[1]].to_numpy()\n",
        "    mue3 = base_interacciones.loc[base_interacciones[\"Target\"]==\"Enrolled\",k[0]+\"__\"+k[1]].to_numpy()\n",
        "\n",
        "    p1 = stats.kruskal(mue1,mue2)[1]\n",
        "    p2 = stats.kruskal(mue1,mue3)[1]\n",
        "    p3 = stats.kruskal(mue2,mue3)[1]\n",
        "\n",
        "    var_interaccion.append(k[0]+\"__\"+k[1])\n",
        "    pv1.append(np.round(p1,2))\n",
        "    pv2.append(np.round(p2,2))\n",
        "    pv3.append(np.round(p3,2))\n",
        "\n",
        "  pxy = pd.DataFrame({'Variable':var_interaccion,'p value':pv1,'p value 2':pv2,'p value 3':pv3})\n",
        "  pxy = criterion_(pxy,[\"p value\",\"p value 2\",\"p value 3\"])\n",
        "\n",
        "  # Razones\n",
        "  raz1 = [(x,y) for x in cuantitativas for y in cuantitativas]\n",
        "  base_razones1 = df.get(cuantitativas).copy()\n",
        "  base_razones1[\"Target\"] = df[\"Target\"].copy()\n",
        "\n",
        "  var_nm, pval, pval2, pval3 = [], [], [], []\n",
        "  for j in raz1:\n",
        "    if j[0]!=j[1]:\n",
        "      base_razones1[j[0]+\"__coc__\"+j[1]] = base_razones1[j[0]] / (base_razones1[j[1]]+0.01)\n",
        "      # Prueba de Kruskal\n",
        "      mue1 = base_razones1.loc[base_razones1[\"Target\"]==\"Graduate\",j[0]+\"__coc__\"+j[1]].to_numpy()\n",
        "      mue2 = base_razones1.loc[base_razones1[\"Target\"]==\"Dropout\",j[0]+\"__coc__\"+j[1]].to_numpy()\n",
        "      mue3 = base_razones1.loc[base_razones1[\"Target\"]==\"Enrolled\",j[0]+\"__coc__\"+j[1]].to_numpy()\n",
        "      p1 = stats.kruskal(mue1,mue2)[1]\n",
        "      p2 = stats.kruskal(mue1,mue3)[1]\n",
        "      p3 = stats.kruskal(mue2,mue3)[1]\n",
        "\n",
        "      # Guardar valores\n",
        "      var_nm.append(j[0]+\"__coc__\"+j[1])\n",
        "      pval.append(np.round(p1,2))\n",
        "      pval2.append(np.round(p2,2))\n",
        "      pval3.append(np.round(p3,2))\n",
        "  prazones = pd.DataFrame({'Variable':var_nm,'p value':pval,'p value 2':pval2, 'p value 3':pval3})\n",
        "  prazones = criterion_(prazones,[\"p value\",\"p value 2\",\"p value 3\"])\n",
        "\n",
        "  # Interacciones categóricas\n",
        "  cb = list(combinations(categoricas,2))\n",
        "  p_value, modalidades, nombre_var = [], [], []\n",
        "\n",
        "  base2 = df.get(categoricas).copy()\n",
        "  for k in base2.columns:\n",
        "    base2[k] = base2[k].map(nombre_)\n",
        "  base2[\"Target\"] = df[\"Target\"].copy()\n",
        "  for k in range(len(cb)):\n",
        "    # Variable con interacción\n",
        "    base2[cb[k][0]] = base2[cb[k][0]]\n",
        "    base2[cb[k][1]] = base2[cb[k][1]]\n",
        "\n",
        "    base2[cb[k][0]+\"__\"+cb[k][1]] = base2[cb[k][0]] + \"__\" + base2[cb[k][1]]\n",
        "\n",
        "    # Prueba chi cuadrado\n",
        "    c1 = pd.DataFrame(pd.crosstab(base2[\"Target\"],base2[cb[k][0]+\"__\"+cb[k][1]]))\n",
        "    pv = stats.chi2_contingency(c1)[1]\n",
        "\n",
        "    # Número de modalidades por categoría\n",
        "    mod_ = len(base2[cb[k][0]+\"__\"+cb[k][1]].unique())\n",
        "\n",
        "    # Guardar p value y modalidades\n",
        "    nombre_var.append(cb[k][0]+\"__\"+cb[k][1])\n",
        "    modalidades.append(mod_)\n",
        "    p_value.append(pv)\n",
        "  pc = pd.DataFrame({'Variable':nombre_var,'Num Modalidades':modalidades,'p value':p_value})\n",
        "\n",
        "  seleccion1 = list(pc.loc[(pc[\"p value\"]<=0.20) & (pc[\"Num Modalidades\"]<=15),\"Variable\"])\n",
        "  sel1 = base2.get(seleccion1)\n",
        "\n",
        "  contador = 0\n",
        "  for k in sel1:\n",
        "    if contador==0:\n",
        "        lb1 = pd.get_dummies(sel1[k],drop_first=True)\n",
        "        lb1.columns = [k + \"_\" + x for x in lb1.columns]\n",
        "    else:\n",
        "        lb2 = pd.get_dummies(sel1[k],drop_first=True)\n",
        "        lb2.columns = [k + \"_\" + x for x in lb2.columns]\n",
        "        lb1 = pd.concat([lb1,lb2],axis=1)\n",
        "    contador = contador + 1\n",
        "\n",
        "  for k in lb1.columns:\n",
        "    lb1[k] = lb1[k].map(indicadora)\n",
        "  lb1[\"Target\"] = df[\"Target\"].copy()\n",
        "\n",
        "  # Interacción cuantitativa categórica\n",
        "  cat_cuanti = [(x,y) for x in cuantitativas for y in categoricas]\n",
        "  v1, v2, pvalores_min, pvalores_max  = [], [], [], []\n",
        "  for j in cat_cuanti:\n",
        "    k1 = j[0]\n",
        "    k2 = j[1]\n",
        "    g1 = pd.get_dummies(df[k2])\n",
        "    lt1 = list(g1.columns)\n",
        "    for k in lt1:\n",
        "      g1[k] = g1[k] * df[k1]\n",
        "    g1[\"Target\"] = df[\"Target\"].copy()\n",
        "\n",
        "    pvalues_c = []\n",
        "    for y in lt1:\n",
        "      mue1 = g1.loc[g1[\"Target\"]==\"Graduate\",y].to_numpy()\n",
        "      mue2 = g1.loc[g1[\"Target\"]==\"Dropout\",y].to_numpy()\n",
        "      mue3 = g1.loc[g1[\"Target\"]==\"Enrolled\",y].to_numpy()\n",
        "\n",
        "      try:\n",
        "        pval = stats.kruskal(mue1,mue2)[1]<=0.20\n",
        "      except ValueError:\n",
        "        pval = 0\n",
        "      try:\n",
        "        pval2 = stats.kruskal(mue1,mue3)[1]<=0.20\n",
        "      except ValueError:\n",
        "        pval2 = 0\n",
        "      try:\n",
        "        pval3 = stats.kruskal(mue2,mue3)[1]<=0.20\n",
        "      except ValueError:\n",
        "        pval3 = 0\n",
        "\n",
        "      pvalues_c.append(np.round(np.sum(np.array([pval,pval2,pval3])),2))\n",
        "    min_ = np.min(pvalues_c) # Se calcula el mínimo p value por categoría\n",
        "    max_ = np.max(pvalues_c)\n",
        "    v1.append(k1)\n",
        "    v2.append(k2)\n",
        "    pvalores_min.append(np.round(min_,2))\n",
        "    pvalores_max.append(np.round(max_,2))\n",
        "  pc2 = pd.DataFrame({'Cuantitativa':v1,'Categórica':v2,'p value':pvalores_min, 'p value max':pvalores_max})\n",
        "\n",
        "  v1 = list(pc2.loc[(pc2[\"p value\"]==3) & (pc2[\"p value max\"]==3),\"Cuantitativa\"])\n",
        "  v2 = list(pc2.loc[(pc2[\"p value\"]==3) & (pc2[\"p value max\"]==3),\"Categórica\"])\n",
        "  for j in range(len(v1)):\n",
        "    if j==0:\n",
        "      g1 = pd.get_dummies(df[v2[j]],drop_first=True)\n",
        "      lt1 = list(g1.columns)\n",
        "      for k in lt1:\n",
        "        g1[k] = g1[k] * df[v1[j]]\n",
        "      g1.columns = [v1[j] + \"_\" + v2[j] + \"_\" + str(x) for x in lt1]\n",
        "    else:\n",
        "      g2 = pd.get_dummies(df[v2[j]],drop_first=True)\n",
        "      lt1 = list(g2.columns)\n",
        "      for k in lt1:\n",
        "        g2[k] = g2[k] * df[v1[j]]\n",
        "      g2.columns = [v1[j] + \"_\" + v2[j] + \"_\" + str(x) for x in lt1]\n",
        "      g1 = pd.concat([g1,g2],axis=1)\n",
        "  g1[\"Target\"] = df[\"Target\"].copy()\n",
        "\n",
        "  # Selección variables al cuadrado\n",
        "  print(\"Selección Cuadrado\")\n",
        "  var_cuad = list(pcuadrado1[\"Variable2\"])\n",
        "  base_modelo1 = base_cuadrado.get(var_cuad+[\"Target\"])\n",
        "  base_modelo1[\"Target\"] = base_modelo1[\"Target\"].map(label_tg)\n",
        "  cov = list(base_modelo1.columns)\n",
        "  cov = [x for x in cov if x not in [\"Target\"]]\n",
        "  X1 = base_modelo1.get(cov)\n",
        "  y1 = base_modelo1.get([\"Target\"])\n",
        "  modelo1 = XGBClassifier()\n",
        "  modelo1 = modelo1.fit(X1,y1)\n",
        "  importancias = modelo1.feature_importances_\n",
        "  imp1 = pd.DataFrame({'Variable':X1.columns,'Importancia':importancias})\n",
        "  imp1[\"Importancia\"] = imp1[\"Importancia\"] * 100 / np.sum(imp1[\"Importancia\"])\n",
        "  imp1 = imp1.sort_values([\"Importancia\"],ascending=False)\n",
        "  imp1.index = range(imp1.shape[0])\n",
        "\n",
        "  # selección Interacciones cuatitativas\n",
        "  print(\"Selección Interacciones cuantitativas\")\n",
        "  var_int = list(pxy[\"Variable\"])\n",
        "  base_modelo2 = base_interacciones.get(var_int+[\"Target\"])\n",
        "  base_modelo2[\"Target\"] = base_modelo2[\"Target\"].map(label_tg)\n",
        "  cov = list(base_modelo2.columns)\n",
        "  cov = [x for x in cov if x not in [\"Target\"]]\n",
        "  X2 = base_modelo2.get(cov)\n",
        "  y2 = base_modelo2.get([\"Target\"])\n",
        "  modelo2 = XGBClassifier()\n",
        "  modelo2 = modelo2.fit(X2,y2)\n",
        "  importancias = modelo2.feature_importances_\n",
        "  imp2 = pd.DataFrame({'Variable':X2.columns,'Importancia':importancias})\n",
        "  imp2[\"Importancia\"] = imp2[\"Importancia\"] * 100 / np.sum(imp2[\"Importancia\"])\n",
        "  imp2 = imp2.sort_values([\"Importancia\"],ascending=False)\n",
        "  imp2.index = range(imp2.shape[0])\n",
        "\n",
        "  # selección razones\n",
        "  print(\"Selección razones\")\n",
        "  var_raz = list(prazones[\"Variable\"])\n",
        "  base_modelo3 = base_razones1.get(var_raz+[\"Target\"])\n",
        "  base_modelo3[\"Target\"] = base_modelo3[\"Target\"].map(label_tg)\n",
        "  cov = list(base_modelo3.columns)\n",
        "  cov = [x for x in cov if x not in [\"Target\"]]\n",
        "  X3 = base_modelo3.get(cov)\n",
        "  y3 = base_modelo3.get([\"Target\"])\n",
        "  modelo3 = XGBClassifier()\n",
        "  modelo3 = modelo3.fit(X3,y3)\n",
        "  importancias = modelo3.feature_importances_\n",
        "  imp3 = pd.DataFrame({'Variable':X3.columns,'Importancia':importancias})\n",
        "  imp3[\"Importancia\"] = imp3[\"Importancia\"] * 100 / np.sum(imp3[\"Importancia\"])\n",
        "  imp3 = imp3.sort_values([\"Importancia\"],ascending=False)\n",
        "  imp3.index = range(imp3.shape[0])\n",
        "\n",
        "  # selección interacciones categóricas\n",
        "  print(\"Selección Interacciones categóricas\")\n",
        "  lb1[\"Target\"] = lb1[\"Target\"].map(label_tg)\n",
        "  cov = list(lb1.columns)\n",
        "  cov = [x for x in cov if x not in [\"Target\"]]\n",
        "  X4 = lb1.get(cov)\n",
        "  y4 = lb1.get([\"Target\"])\n",
        "  modelo4 = XGBClassifier()\n",
        "  modelo4 = modelo4.fit(X4,y4)\n",
        "  importancias = modelo4.feature_importances_\n",
        "  imp4 = pd.DataFrame({'Variable':X4.columns,'Importancia':importancias})\n",
        "  imp4[\"Importancia\"] = imp4[\"Importancia\"] * 100 / np.sum(imp4[\"Importancia\"])\n",
        "  imp4 = imp4.sort_values([\"Importancia\"],ascending=False)\n",
        "  imp4.index = range(imp4.shape[0])\n",
        "\n",
        "  # selección interacciones cuantitativas y categóricas\n",
        "  print(\"Selección interacciones cuantitativas y categóricas\")\n",
        "  g1[\"Target\"] = g1[\"Target\"].map(label_tg)\n",
        "  cov = list(g1.columns)\n",
        "  cov = [x for x in cov if x not in [\"Target\"]]\n",
        "  X5 = g1.get(cov)\n",
        "  y5 = g1.get([\"Target\"])\n",
        "  modelo5 = XGBClassifier()\n",
        "  modelo5 = modelo5.fit(X5,y5)\n",
        "  importancias = modelo5.feature_importances_\n",
        "  imp5 = pd.DataFrame({'Variable':X5.columns,'Importancia':importancias})\n",
        "  imp5[\"Importancia\"] = imp5[\"Importancia\"] * 100 / np.sum(imp5[\"Importancia\"])\n",
        "  imp5 = imp5.sort_values([\"Importancia\"],ascending=False)\n",
        "  imp5.index = range(imp5.shape[0])\n",
        "\n",
        "  # variables más importantes\n",
        "  c2 = list(imp1.iloc[0:3,0]) # Variables al cuadrado\n",
        "  cxy = list(imp2.iloc[0:3,0]) # Interacciones cuantitativas\n",
        "  razxy = list(imp3.iloc[0:3,0]) # Razones\n",
        "  catxy = list(imp4.iloc[0:3,0]) # Interacciones categóricas\n",
        "  cuactxy = list(imp5.iloc[0:3,0]) # Interacción cuantitativa y categórica\n",
        "\n",
        "  # Preparación Datos\n",
        "  D1 = df.get(cuantitativas).copy()\n",
        "  D2 = df.get(categoricas).copy()\n",
        "  for k in categoricas:\n",
        "    D2[k] = D2[k].map(nombre_)\n",
        "  D4 = D2.copy()\n",
        "  # Variables al cuadrado (Activar D1)\n",
        "  cuadrado = [re.findall(r'(.+)_\\d+', item) for item in c2]\n",
        "  cuadrado = [x[0] for x in cuadrado]\n",
        "  for k in cuadrado:\n",
        "    D1[k+\"_2\"] = D1[k] ** 2\n",
        "  # Interacciones cuantitativas (Activar D1)\n",
        "  result = [re.findall(r'([A-Za-z\\s\\(\\)0-9]+)', item) for item in cxy]\n",
        "  for k in result:\n",
        "    D1[k[0]+\"__\"+k[1]] = D1[k[0]] * D1[k[1]]\n",
        "  # Razones\n",
        "  result2 = [re.findall(r'(.+)__coc__(.+)', item) for item in razxy]\n",
        "  for k in result2:\n",
        "    k2 = k[0]\n",
        "    D1[k2[0]+\"__coc__\"+k2[1]] = D1[k2[0]] / (D1[k2[1]]+0.01)\n",
        "  # Interacciones categóricas\n",
        "  result3 = [re.search(r'([^_]+__[^_]+)', item).group(1).split('__') for item in catxy]\n",
        "  for k in result3:\n",
        "    D4[k[0]+\"__\"+k[1]] = D4[k[0]] + \"_\" + D4[k[1]]\n",
        "  # Interacción cuantitativa vs categórica\n",
        "  D5 = df.copy()\n",
        "  result4 = [re.search(r'(.+?)_(.+?)_\\d+', item).groups() for item in cuactxy]\n",
        "  contador = 0\n",
        "  for k in result4:\n",
        "    col1, col2 = k[1], k[0] # categórica, cuantitativa\n",
        "    if contador == 0:\n",
        "      D51 = pd.get_dummies(D5[col1],drop_first=True)\n",
        "      for j in D51.columns:\n",
        "        D51[j] = D51[j] * D5[col2]\n",
        "      D51.columns = [col2+\"_\"+col1+\"_\"+ str(x) for x in D51.columns]\n",
        "    else:\n",
        "      D52 = pd.get_dummies(D5[col1],drop_first=True)\n",
        "      for j in D52.columns:\n",
        "        D52[j] = D52[j] * D5[col2]\n",
        "      D52.columns = [col2+\"_\"+col1+\"_\"+ str(x) for x in D52.columns]\n",
        "      D51 = pd.concat([D51,D52],axis=1)\n",
        "    contador = contador + 1\n",
        "  # Base Final\n",
        "  B1 = pd.concat([D1,D4],axis=1)\n",
        "  base_modelo = pd.concat([B1,D51],axis=1)\n",
        "  base_modelo[\"Target\"] = df[\"Target\"].copy()\n",
        "  base_modelo[\"Target\"] = base_modelo[\"Target\"].map(label_tg)\n",
        "  return base_modelo, cuantitativas, categoricas, cuadrado, result, result2, result3, result4"
      ],
      "metadata": {
        "id": "5h19Rpf62QT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AUTOML_PyCaret_train_tunning_evaluate_model(base_modelo,train_size=0.7):\n",
        "  def prueba_kr(x):\n",
        "    if x<=0.10:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def criterion_(df,columns):\n",
        "    for k in columns:\n",
        "      df[k] = df[k].map(prueba_kr)\n",
        "    df[\"criterio\"] = np.sum(df.get(columns),axis=1)\n",
        "    df[\"criterio\"] = df.apply(lambda row: 1 if row[\"criterio\"]==3 else 0,axis = 1)\n",
        "    return df\n",
        "\n",
        "  def nombre_(x):\n",
        "    return \"C\"+str(x)\n",
        "\n",
        "  def indicadora(x):\n",
        "    if x==True:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def label_tg(x):\n",
        "    if x==\"Dropout\":\n",
        "      return 0\n",
        "    elif x==\"Enrolled\":\n",
        "      return 1\n",
        "    else:\n",
        "      return 2\n",
        "\n",
        "  def label_tg_inv(x):\n",
        "    if x==0:\n",
        "      return \"Dropout\"\n",
        "    elif x==1:\n",
        "      return \"Enrolled\"\n",
        "    else:\n",
        "      return \"Graduate\"\n",
        "\n",
        "  formatos = pd.DataFrame(base_modelo.dtypes).reset_index()\n",
        "  formatos.columns = [\"Variable\",\"Formato\"]\n",
        "  cuantitativas_bm = list(formatos.loc[formatos[\"Formato\"]!=\"object\",][\"Variable\"])\n",
        "  categoricas_bm = list(formatos.loc[formatos[\"Formato\"]==\"object\",][\"Variable\"])\n",
        "  cuantitativas_bm = [x for x in cuantitativas_bm if x not in [\"Target\"]]\n",
        "  categoricas_bm = [x for x in categoricas_bm if x not in [\"Target\"]]\n",
        "\n",
        "  exp_clf101 = setup(data=base_modelo,target='Target',session_id=123,train_size=train_size,\n",
        "  numeric_features = cuantitativas_bm,categorical_features = categoricas_bm)\n",
        "\n",
        "  best_model = compare_models(include=['lightgbm', 'xgboost', 'lr'])\n",
        "\n",
        "  if best_model.__class__.__name__ == 'LGBMClassifier':\n",
        "    dt = create_model(\"lightgbm\")\n",
        "    param_grid_bayesian = {\n",
        "    'n_estimators': [50,100,200],\n",
        "    'max_depth': [3,5,7],\n",
        "    'min_child_samples': [50,150,200]}\n",
        "    # Perform Bayesian Search\n",
        "    tuned_dt = tune_model(dt, custom_grid=param_grid_bayesian, search_library='scikit-optimize', search_algorithm='bayesian',fold=5)\n",
        "\n",
        "  if best_model.__class__.__name__ == 'XGBClassifier':\n",
        "    dt = create_model(\"xgboost\")\n",
        "    param_grid_bayesian = {\n",
        "    'n_estimators': [50,100,200],\n",
        "    'max_depth': [3,5,7]}\n",
        "    # Perform Bayesian Search\n",
        "    tuned_dt = tune_model(dt, custom_grid=param_grid_bayesian, search_library='scikit-optimize', search_algorithm='bayesian',fold=5)\n",
        "\n",
        "  if best_model.__class__.__name__ == 'LogisticRegression':\n",
        "    dt = create_model(\"lr\")\n",
        "    param_grid_bayesian = {\n",
        "    'C': [x for x in np.arange(0.1,5.1,0.1)]}\n",
        "    # Perform Bayesian Search\n",
        "    tuned_dt = tune_model(dt, custom_grid=param_grid_bayesian, search_library='scikit-optimize', search_algorithm='bayesian',fold=5)\n",
        "\n",
        "  # Predicciones\n",
        "  predictions_test = predict_model(tuned_dt)\n",
        "  predictions_train = predict_model(tuned_dt, data=exp_clf101.get_config('X_train'))\n",
        "  y_train = get_config('y_train')\n",
        "  y_test = get_config('y_test')\n",
        "  accuracy_train = accuracy_score(y_train,predictions_train[\"prediction_label\"])\n",
        "  accuracy_test = accuracy_score(y_test,predictions_test[\"prediction_label\"])\n",
        "\n",
        "  # Modelo final y completo\n",
        "  final_dt = finalize_model(tuned_dt)\n",
        "\n",
        "  return final_dt, accuracy_train, accuracy_test"
      ],
      "metadata": {
        "id": "W1aO5ccm2Q4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AUTOML_PyCaret_forecast_pred(path,prueba,final_dt,cuantitativas, categoricas, cuadrado, result, result2, result3, result4):\n",
        "  def prueba_kr(x):\n",
        "    if x<=0.10:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def criterion_(df,columns):\n",
        "    for k in columns:\n",
        "      df[k] = df[k].map(prueba_kr)\n",
        "    df[\"criterio\"] = np.sum(df.get(columns),axis=1)\n",
        "    df[\"criterio\"] = df.apply(lambda row: 1 if row[\"criterio\"]==3 else 0,axis = 1)\n",
        "    return df\n",
        "\n",
        "  def nombre_(x):\n",
        "    return \"C\"+str(x)\n",
        "\n",
        "  def indicadora(x):\n",
        "    if x==True:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def label_tg(x):\n",
        "    if x==\"Dropout\":\n",
        "      return 0\n",
        "    elif x==\"Enrolled\":\n",
        "      return 1\n",
        "    else:\n",
        "      return 2\n",
        "\n",
        "  def label_tg_inv(x):\n",
        "    if x==0:\n",
        "      return \"Dropout\"\n",
        "    elif x==1:\n",
        "      return \"Enrolled\"\n",
        "    else:\n",
        "      return \"Graduate\"\n",
        "  # Variables cuantitativas (Activar D1)\n",
        "  D1 = prueba.get(cuantitativas).copy()\n",
        "  # Variables categóricas\n",
        "  D2 = prueba.get(categoricas).copy()\n",
        "  for k in categoricas:\n",
        "    D2[k] = D2[k].map(nombre_)\n",
        "  D4 = D2.copy()\n",
        "  # Variables al cuadrado (Activar D1)\n",
        "  for k in cuadrado:\n",
        "    D1[k+\"_2\"] = D1[k] ** 2\n",
        "  # Interacciones cuantitativas (Activar D1)\n",
        "  for k in result:\n",
        "    D1[k[0]+\"__\"+k[1]] = D1[k[0]] * D1[k[1]]\n",
        "  # Razones\n",
        "  for k in result2:\n",
        "    k2 = k[0]\n",
        "    D1[k2[0]+\"__coc__\"+k2[1]] = D1[k2[0]] / (D1[k2[1]]+0.01)\n",
        "\n",
        "  # Interacciones categóricas\n",
        "  for k in result3:\n",
        "    D4[k[0]+\"__\"+k[1]] = D4[k[0]] + \"_\" + D4[k[1]]\n",
        "\n",
        "  # Interacción cuantitativa vs categórica\n",
        "  D5 = prueba.copy()\n",
        "  contador = 0\n",
        "  for k in result4:\n",
        "    col1, col2 = k[1], k[0] # categórica, cuantitativa\n",
        "    if contador == 0:\n",
        "      D51 = pd.get_dummies(D5[col1],drop_first=True)\n",
        "      for j in D51.columns:\n",
        "        D51[j] = D51[j] * D5[col2]\n",
        "      D51.columns = [col2+\"_\"+col1+\"_\"+ str(x) for x in D51.columns]\n",
        "    else:\n",
        "      D52 = pd.get_dummies(D5[col1],drop_first=True)\n",
        "      for j in D52.columns:\n",
        "        D52[j] = D52[j] * D5[col2]\n",
        "      D52.columns = [col2+\"_\"+col1+\"_\"+ str(x) for x in D52.columns]\n",
        "      D51 = pd.concat([D51,D52],axis=1)\n",
        "    contador = contador + 1\n",
        "\n",
        "  B1 = pd.concat([D1,D4],axis=1)\n",
        "  base_modelo2 = pd.concat([B1,D51],axis=1)\n",
        "  df_test = base_modelo2.copy()\n",
        "  predictions = predict_model(final_dt, data=df_test)\n",
        "\n",
        "  result_k = pd.DataFrame({'id': prueba[\"id\"],'Target': predictions['prediction_label']})\n",
        "  result_k[\"Target\"] = result_k[\"Target\"].map(label_tg_inv)\n",
        "  result_k.to_csv(path + 'subbmision_albert0.csv', index=False,sep=\",\")\n",
        "  return result_k"
      ],
      "metadata": {
        "id": "z_3tSF_v2T0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Subbmit_kaggle(path,user,token):\n",
        "  def prueba_kr(x):\n",
        "    if x<=0.10:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def criterion_(df,columns):\n",
        "    for k in columns:\n",
        "      df[k] = df[k].map(prueba_kr)\n",
        "    df[\"criterio\"] = np.sum(df.get(columns),axis=1)\n",
        "    df[\"criterio\"] = df.apply(lambda row: 1 if row[\"criterio\"]==3 else 0,axis = 1)\n",
        "    return df\n",
        "\n",
        "  def nombre_(x):\n",
        "    return \"C\"+str(x)\n",
        "\n",
        "  def indicadora(x):\n",
        "    if x==True:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def label_tg(x):\n",
        "    if x==\"Dropout\":\n",
        "      return 0\n",
        "    elif x==\"Enrolled\":\n",
        "      return 1\n",
        "    else:\n",
        "      return 2\n",
        "\n",
        "  def label_tg_inv(x):\n",
        "    if x==0:\n",
        "      return \"Dropout\"\n",
        "    elif x==1:\n",
        "      return \"Enrolled\"\n",
        "    else:\n",
        "      return \"Graduate\"\n",
        "  # Configurar las credenciales de Kaggle\n",
        "  os.environ['KAGGLE_USERNAME'] = user\n",
        "  os.environ['KAGGLE_KEY'] = token\n",
        "\n",
        "  # Crear instancia de la API de Kaggle y autenticar\n",
        "  api = KaggleApi()\n",
        "  api.authenticate()\n",
        "\n",
        "  # Aceptar las reglas de la competencia (intenta este paso primero)\n",
        "  competition_name = 'playground-series-s4e6'\n",
        "  # Descargar los archivos de la competencia\n",
        "  download_path = path + 'data/'\n",
        "  api.competition_download_files(competition_name, path=download_path)\n",
        "\n",
        "  # Descomprimir los archivos descargados\n",
        "  import zipfile\n",
        "  for item in os.listdir(download_path):\n",
        "    if item.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(os.path.join(download_path, item), 'r')\n",
        "      zip_ref.extractall(download_path)\n",
        "      zip_ref.close()\n",
        "      print(f\"Unzipped {item}\")\n",
        "  api.competition_submit(file_name=path + \"subbmision_albert0.csv\",\n",
        "  message=\"First submission\",competition=\"playground-series-s4e6\")\n",
        "  return True"
      ],
      "metadata": {
        "id": "YmsGuY_k2Z8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}